{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Global Vector for Word Represtation(GLOVE)**\n",
        "\n",
        "\n",
        "\n",
        "A method to  generate word embeddings based on word co-occurance and matrix factorization.\n",
        "\n"
      ],
      "metadata": {
        "id": "OgV-6Rg6v4K7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2fXSMLGo0Vr",
        "outputId": "bd6c5397-ecca-45c4-f317-b4434a90e6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip -d glove.6B"
      ],
      "metadata": {
        "id": "emFhnGL0pOfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "\n",
        "glove_file = \"glove.6B/glove.6B.100d.txt\"\n",
        "glove_embeddings = {}\n",
        "with open(glove_file, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.array(values[1:], dtype='float32')\n",
        "        glove_embeddings[word] = vector"
      ],
      "metadata": {
        "id": "gT986Q7UpSPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"example\"\n",
        "if word in glove_embeddings:\n",
        "    word_vector = glove_embeddings[word]\n",
        "else:\n",
        "    word_vector = None\n"
      ],
      "metadata": {
        "id": "yQ0IOosznyMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hk8Sw9FpiLK",
        "outputId": "2e3c742a-9efb-4c03-ecee-2ee56d4b0813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.12617    0.61724    0.22581    0.39868    0.16111    0.1523\n",
            " -0.14715   -0.29447   -0.27348   -0.13753   -0.20898   -0.73436\n",
            "  0.14144    0.15048    0.09179    0.018613   0.22539    0.15979\n",
            " -0.16935    0.42716    0.042284  -0.3477    -0.11413    0.12222\n",
            " -0.025027  -0.20805   -0.067264  -0.2956    -0.30807   -0.32903\n",
            "  0.19059    0.77141   -0.19332   -0.31069    0.26745    0.32231\n",
            "  0.2065     0.10497    0.49425   -0.38322   -0.12802   -0.069906\n",
            " -0.14828    0.085369  -0.18141    0.14688    0.60968   -0.21131\n",
            " -0.29148   -0.52773    0.59508    0.017369   0.15342    0.81925\n",
            " -0.20643   -2.0378    -0.11884   -0.16826    1.5288     0.15756\n",
            " -0.4994     0.39305    0.12672   -0.10968    1.3671    -0.21006\n",
            "  0.15684    0.0063801  0.43836   -0.18765   -0.29088    0.18619\n",
            "  0.085402   0.13985    0.40794   -0.14811    0.26702   -0.19142\n",
            " -0.6189     0.0091217  0.34971   -0.24079   -0.52476   -0.25071\n",
            " -1.5681     0.22101    0.046796  -0.62616   -0.043358  -0.42865\n",
            " -0.0057843 -0.22611    0.074171   0.091597  -0.40751   -0.08359\n",
            " -0.48413   -1.0718     0.52827    0.058813 ]\n"
          ]
        }
      ]
    }
  ]
}